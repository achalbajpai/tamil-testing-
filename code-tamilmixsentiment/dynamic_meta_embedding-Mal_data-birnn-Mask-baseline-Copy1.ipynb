{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bharaj/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import string\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from gensim.models import *\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "import keras.backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.callbacks import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 14)\n",
    "\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6739, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown state</td>\n",
       "      <td>Ichayan fans pinne mmade ettan fansm ivde oru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not-malayalam</td>\n",
       "      <td>Tovi ðŸ¥° Best Wishes From #Kunjikka Fans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown state</td>\n",
       "      <td>Urutty koll .nallavanaaya unniyaya saiju kuru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not-malayalam</td>\n",
       "      <td>Pls support me pls       My channel subscribe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Kalki super hit akum enn Bonny parayan paranju</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                               text\n",
       "0  unknown state    Ichayan fans pinne mmade ettan fansm ivde oru...\n",
       "1  not-malayalam              Tovi ðŸ¥° Best Wishes From #Kunjikka Fans\n",
       "2  unknown state    Urutty koll .nallavanaaya unniyaya saiju kuru...\n",
       "3  not-malayalam    Pls support me pls       My channel subscribe...\n",
       "4       Positive      Kalki super hit akum enn Bonny parayan paranju"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### READ DATA ###\n",
    "\n",
    "df = pd.read_csv('whole_mal.tsv',sep='\\t',names=['category','text'])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1e87a2fda0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LABEL DISTRIBUTION ###\n",
    "\n",
    "df.category.value_counts().plot.pie(figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SIMPLE CLEAN OF TEXT ###\n",
    "\n",
    "df['text'] = df.text.str.lower().str.replace(r'['+string.digits+string.punctuation+']', ' ')\n",
    "df['text'] = df['text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#y = df['category'].tolist()\n",
    "#y=np.array(y)\n",
    "#type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SPLIT INTO TRAIN/TEST ###\n",
    "y=df['category']\n",
    "#y = pd.get_dummies(df['category']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].tolist(), y, random_state=5, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4616         Positive \n",
       "5193         Positive \n",
       "4502    not-malayalam \n",
       "4186         Positive \n",
       "4037    unknown state \n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(y_train))\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=pd.get_dummies(y_train).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=pd.get_dummies(y_test).values\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ente', 'ponnnuuuuuuu', 'lalettaaa', 'baaki', 'oke', 'kili', 'vannit', 'parayam'] unknown state \n"
     ]
    }
   ],
   "source": [
    "print(X_train[0],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'unknown state ',\n",
       " 1: 'not-malayalam ',\n",
       " 2: 'Positive ',\n",
       " 3: 'Negative ',\n",
       " 4: 'Mixed feelings '}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MAP LABEL ###\n",
    "\n",
    "diz_label = {}\n",
    "for i,label in enumerate(df.category.factorize()[1]):\n",
    "    diz_label[i] = label\n",
    "    \n",
    "diz_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TRAIN WORD2VEC AND FASTTEXT ###\n",
    "\n",
    "w2v = Word2Vec(size=100, window=5, min_count=4, seed=33)\n",
    "w2v.build_vocab(X_train)\n",
    "w2v.train(X_train, total_examples=w2v.corpus_count, epochs=10)\n",
    "\n",
    "ft = FastText(size=100, window=5, min_count=4, seed=33)\n",
    "ft.build_vocab(X_train)\n",
    "ft.train(X_train, total_examples=ft.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5391, 200) (1348, 200)\n"
     ]
    }
   ],
   "source": [
    "### TRANSFORM ORIGINAL TEXT INTO SEQUENCES AND COMPUTE PADDING ###\n",
    "\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(lower=True, split='')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "sequence_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequence_train = pad_sequences(sequence_train, maxlen=max_len)\n",
    "\n",
    "sequence_test = tokenizer.texts_to_sequences(X_test)\n",
    "sequence_test = pad_sequences(sequence_test, maxlen=max_len)\n",
    "\n",
    "sequence_train = np.asarray(sequence_train)\n",
    "sequence_test = np.asarray(sequence_test)\n",
    "\n",
    "print(sequence_train.shape, sequence_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "glove_file = open('/home/bharaj/third_work/tools/fastText/word_vectors/ml_roman.vec', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in vocabulary 1763\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_fasttext_ml_roman = zeros((len(tokenizer.word_index) + 1, 100))\n",
    "pas = 0\n",
    "for word,i in tokenizer.word_index.items():    \n",
    "    try:\n",
    "        embedding_vector = embeddings_dictionary.get(word)\n",
    "        embedding_matrix_fasttext_ml_roman[i] = embedding_vector\n",
    "    except:\n",
    "        pas+=1\n",
    "        \n",
    "print('not in vocabulary', pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GET TRAINED WEIGHTS FOR EACH WORD FROM WORD2VEC ###\n",
    "\n",
    "# embedding_matrix_w2v = np.random.random((len(tokenizer.word_index) + 1, 100))\n",
    "\n",
    "# pas = 0\n",
    "# for word,i in tokenizer.word_index.items():\n",
    "    \n",
    "#     try:\n",
    "#         embedding_matrix_w2v[i] = w2v.wv[word]\n",
    "#     except:\n",
    "#         pas+=1\n",
    "        \n",
    "# print('not in vocabulary', pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in vocabulary 0\n"
     ]
    }
   ],
   "source": [
    "### GET TRAINED WEIGHTS FOR EACH WORD FROM FASTTEXT ###\n",
    "\n",
    "embedding_matrix_ft = np.random.random((len(tokenizer.word_index) + 1, 100))\n",
    "\n",
    "pas = 0\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    \n",
    "    try:\n",
    "        embedding_matrix_ft[i] = ft.wv[word]\n",
    "    except:\n",
    "        pas+=1\n",
    "        \n",
    "print('not in vocabulary', pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DEFINE INPUT LAYER FOR EMBEDDINGS READING AND CONCATENATION ###\n",
    "\n",
    "def Concat_Emb(list_emb, maxlen):\n",
    "    \n",
    "    inputs = []\n",
    "    output = []\n",
    "    for embedding in list_emb:\n",
    "        \n",
    "        inp = Input(shape=(maxlen,))\n",
    "        emb = Embedding(len(tokenizer.word_index) + 1, 100, weights=[embedding], trainable=False)(inp)\n",
    "        emb = Reshape((-1,100,1))(emb)\n",
    "        \n",
    "        inputs.append(inp)\n",
    "        output.append(emb)\n",
    "        \n",
    "    concat = Concatenate(axis=-1)(output)\n",
    "    \n",
    "    return Model(inputs, concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0110 15:29:51.868969 139771456558848 deprecation_wrapper.py:119] From /home/bharaj/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0110 15:29:51.970487 139771456558848 deprecation_wrapper.py:119] From /home/bharaj/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0110 15:29:51.978865 139771456558848 deprecation_wrapper.py:119] From /home/bharaj/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0110 15:29:51.995384 139771456558848 deprecation_wrapper.py:119] From /home/bharaj/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0110 15:29:51.996676 139771456558848 deprecation_wrapper.py:119] From /home/bharaj/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 100)     1371200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 200, 100)     1371200     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 200, 100, 1)  0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 200, 100, 1)  0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200, 100, 2)  0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,742,400\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,742,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### TRY Concat_Emb ###\n",
    "read_emb = Concat_Emb([embedding_matrix_fasttext_ml_roman, embedding_matrix_ft], maxlen=max_len)\n",
    "#read_emb = Concat_Emb([embedding_matrix_w2v, embedding_matrix_ft], maxlen=max_len)\n",
    "read_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DEFINE DME AND CDME BLOCKS ###\n",
    "\n",
    "def DME(maxlen):\n",
    "\n",
    "    inp = Input(shape=(maxlen, 100, 2))\n",
    "    x = Reshape((maxlen, -1))(inp)\n",
    "    #x=Masking(mask_value=0)(x)\n",
    "    x = LSTM(2, return_sequences=True)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Reshape((maxlen, 1, 2))(x)\n",
    "    x = multiply([inp, x])\n",
    "    out = Lambda(lambda t: K.sum(t, axis=-1))(x)\n",
    "    \n",
    "    return Model(inp, out)\n",
    "\n",
    "def CDME(maxlen, latent_dim=2):\n",
    "    \n",
    "    inp = Input(shape=(maxlen, 100, 2))\n",
    "    x = Reshape((maxlen, -1))(inp)\n",
    "    x = Bidirectional(LSTM(latent_dim, return_sequences=True))(x)\n",
    "    x = Lambda(lambda t: [t[:,:,:int(latent_dim/2+1)], t[:,:,int(latent_dim/2+1):]])(x)\n",
    "    x = Maximum()(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Reshape((maxlen, 1, 2))(x)\n",
    "    x = multiply([inp, x])\n",
    "    out = Lambda(lambda t: K.sum(t, axis=-1))(x)\n",
    "    \n",
    "    return Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 200, 100)     1371200     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 200, 100)     1371200     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 200, 100, 1)  0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 200, 100, 1)  0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 200, 100, 2)  0           reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_6 (Model)                 (None, 200, 100)     1624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, 200, 100)     0           model_6[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 200, 256)     234496      masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 64)           73984       bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            325         bidirectional_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 3,052,829\n",
      "Trainable params: 310,429\n",
      "Non-trainable params: 2,742,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### DEFINE NETWORK WITH DME ###\n",
    "concat_inp = Concat_Emb([embedding_matrix_fasttext_ml_roman, embedding_matrix_ft], maxlen=max_len)\n",
    "#concat_inp = Concat_Emb([embedding_matrix_w2v, embedding_matrix_ft], maxlen=max_len)\n",
    "dme = DME(max_len)\n",
    "x = dme(concat_inp.output)\n",
    "x= Masking(mask_value=0)(x)\n",
    "x = Bidirectional(LSTM(128, dropout=0.2, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(32, dropout=0.2))(x)\n",
    "out = Dense(y_train.shape[1], activation='softmax',kernel_regularizer=regularizers.l1(0.01))(x)\n",
    "\n",
    "dme_model = Model(concat_inp.input, out)\n",
    "dme_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=10)\n",
    "mc = ModelCheckpoint('best_DME_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "dme_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4851 samples, validate on 540 samples\n",
      "Epoch 1/20\n",
      " - 102s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.05741\n",
      "Epoch 2/20\n",
      " - 94s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.05741\n",
      "Epoch 3/20\n",
      " - 95s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.05741\n",
      "Epoch 4/20\n",
      " - 93s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.05741\n",
      "Epoch 5/20\n",
      " - 93s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.05741\n",
      "Epoch 6/20\n",
      " - 92s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.05741\n",
      "Epoch 7/20\n",
      " - 95s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.05741\n",
      "Epoch 8/20\n",
      " - 93s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.05741\n",
      "Epoch 9/20\n",
      " - 92s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.05741\n",
      "Epoch 10/20\n",
      " - 93s - loss: nan - acc: 0.0623 - val_loss: nan - val_acc: 0.0574\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.05741\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=dme_model.fit([sequence_train]*2, y_train, batch_size=128, epochs=20, verbose=2, validation_split=0.1,class_weight=class_weights,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = 'best_dme_model.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a5dc682bf660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdme_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_DME_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = 'best_dme_model.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "dme_model=load_model('best_DME_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([diz_label[i] for i in np.argmax(y_test, axis=1)], \n",
    "                            [diz_label[i] for i in np.argmax(dme_model.predict([sequence_test]*2), axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix([diz_label[i] for i in np.argmax(y_test, axis=1)], \n",
    "                              [diz_label[i] for i in np.argmax(dme_model.predict([sequence_test]*2), axis=1)])\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plot_confusion_matrix(cnf_matrix, classes=list(diz_label.values()), title=\"Confusion matrix DME\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE NETWORK WITH CDME ###\n",
    "\n",
    "concat_inp = Concat_Emb([embedding_matrix_fasttext_ml_roman, embedding_matrix_ft], maxlen=max_len)\n",
    "cdme = CDME(max_len)\n",
    "x = cdme(concat_inp.output)\n",
    "x=Masking(mask_value=0)(x)\n",
    "x = Bidirectional(LSTM(128, dropout=0.2, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(32, dropout=0.2))(x)\n",
    "out = Dense(y_train.shape[1], activation='softmax',kernel_regularizer=regularizers.l1(0.01))(x)\n",
    "\n",
    "cdme_model = Model(concat_inp.input, out)\n",
    "cdme_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=10)\n",
    "mc = ModelCheckpoint('best_CDME_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "cdme_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=cdme_model.fit([sequence_train]*2, y_train, batch_size=128, epochs=20, verbose=2, validation_split=0.1,class_weight=class_weights,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdme_model=load_model('best_CDME_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([diz_label[i] for i in np.argmax(y_test, axis=1)], \n",
    "                            [diz_label[i] for i in np.argmax(cdme_model.predict([sequence_test]*2), axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix([diz_label[i] for i in np.argmax(y_test, axis=1)], \n",
    "                              [diz_label[i] for i in np.argmax(cdme_model.predict([sequence_test]*2), axis=1)])\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plot_confusion_matrix(cnf_matrix, classes=list(diz_label.values()), title=\"Confusion matrix CDME\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
